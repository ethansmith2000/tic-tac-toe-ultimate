{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100000/100000 [00:07<00:00, 12651.00it/s]\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "class TicTacToe:\n",
    "    def __init__(self):\n",
    "        self.board = [0] * 9  # 0 for empty, 1 for X, -1 for O\n",
    "        self.game_over = False\n",
    "        self.current_player = 1  # X starts first\n",
    "\n",
    "    def is_valid_move(self, position):\n",
    "        return self.board[position] == 0\n",
    "\n",
    "    def make_move(self, position):\n",
    "        if not self.is_valid_move(position):\n",
    "            return False\n",
    "        self.board[position] = self.current_player\n",
    "        if self.check_winner():\n",
    "            self.game_over = True\n",
    "        return True\n",
    "\n",
    "    def change_turn(self):\n",
    "        self.current_player *= -1\n",
    "\n",
    "    def check_winner(self):\n",
    "        # Horizontal, vertical, and diagonal checks\n",
    "        wins = [(0, 1, 2), (3, 4, 5), (6, 7, 8),\n",
    "                (0, 3, 6), (1, 4, 7), (2, 5, 8),\n",
    "                (0, 4, 8), (2, 4, 6)]\n",
    "        for a, b, c in wins:\n",
    "            if self.board[a] == self.board[b] == self.board[c] != 0:\n",
    "                return True\n",
    "        return False\n",
    "\n",
    "    def get_empty_positions(self):\n",
    "        return [i for i, x in enumerate(self.board) if x == 0]\n",
    "\n",
    "    def reset(self):\n",
    "        self.board = [0] * 9\n",
    "        self.game_over = False\n",
    "        self.current_player = 1\n",
    "\n",
    "\n",
    "class QLearningAgent:\n",
    "    def __init__(self, alpha=0.1, gamma=0.9, epsilon=0.2):\n",
    "        # Separate Q-tables for X and O\n",
    "        self.q_tables = {1: {}, -1: {}}  # 1 for X, -1 for O\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.epsilon = epsilon\n",
    "\n",
    "    def get_q_value(self, player, state, action):\n",
    "        return self.q_tables[player].get((tuple(state), action), 0)\n",
    "\n",
    "    def choose_action(self, player, state, available_actions):\n",
    "        if not available_actions:\n",
    "            return None\n",
    "        if random.random() < self.epsilon:\n",
    "            return random.choice(available_actions)\n",
    "        qs = [self.get_q_value(player, state, a) for a in available_actions]\n",
    "        max_q = max(qs)\n",
    "        return available_actions[qs.index(max_q)]\n",
    "\n",
    "\n",
    "    def update_q_value(self, player, state, action, reward, next_state, next_available_actions, opponent):\n",
    "        current_q = self.get_q_value(player, state, action)\n",
    "        best_opponent_action = max([self.get_q_value(opponent, next_state, a) for a in next_available_actions], default=0)\n",
    "        self.q_tables[player][(tuple(state), action)] = current_q + self.alpha * (reward - self.gamma * best_opponent_action - current_q)\n",
    "\n",
    "\n",
    "def train_agent(agent, episodes=1000):\n",
    "    game = TicTacToe()\n",
    "    for _ in tqdm(range(episodes)):\n",
    "        game.reset()\n",
    "        while not game.game_over:\n",
    "            state = game.board.copy()\n",
    "            current_player = game.current_player\n",
    "            available_actions = game.get_empty_positions()\n",
    "            action = agent.choose_action(current_player, state, available_actions)\n",
    "            if action is not None:\n",
    "                game.make_move(action)\n",
    "                next_state = game.board.copy()\n",
    "                next_available_actions = game.get_empty_positions()\n",
    "\n",
    "                if game.game_over:\n",
    "                    if game.check_winner():\n",
    "                        reward = 1 if game.current_player == current_player else -1\n",
    "                    else:\n",
    "                        reward = -0.25  # It's a tie\n",
    "                else:\n",
    "                    reward = 0\n",
    "\n",
    "                opponent = -current_player\n",
    "                agent.update_q_value(current_player, state, action, reward, next_state, next_available_actions, opponent)\n",
    "                game.change_turn()\n",
    "            if game.game_over or action is None:\n",
    "                break\n",
    "\n",
    "\n",
    "# Adjust make_move and check_winner accordingly if needed.\n",
    "agent = QLearningAgent(alpha=0.05, gamma=0.8, epsilon=0.1)\n",
    "train_agent(agent, episodes=100_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out of 100 games:\n",
      "Wins: 84\n",
      "Losses: 4\n",
      "Ties: 12\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "def play_against_random(agent, games=100):\n",
    "    wins = 0\n",
    "    losses = 0\n",
    "    ties = 0\n",
    "    agent.epsilon = 0  # No exploration\n",
    "    for _ in range(games):\n",
    "        game = TicTacToe()\n",
    "        random_player = random.choice([-1, 1])  # Randomly decide who starts first\n",
    "\n",
    "        while not game.game_over:\n",
    "            available_actions = game.get_empty_positions()\n",
    "            if not available_actions:  # No available actions, board is full\n",
    "                ties += 1\n",
    "                break\n",
    "\n",
    "            if game.current_player == random_player:\n",
    "                # Random player's turn\n",
    "                action = random.choice(available_actions)\n",
    "                game.make_move(action)\n",
    "            else:\n",
    "                # Agent's turn\n",
    "                action = agent.choose_action(game.current_player, game.board, available_actions)\n",
    "                if action is not None:\n",
    "                    game.make_move(action)\n",
    "            \n",
    "            # Check game status\n",
    "            if game.check_winner():\n",
    "                if game.current_player != random_player:\n",
    "                    wins += 1\n",
    "                elif game.current_player == random_player:\n",
    "                    losses += 1\n",
    "                game.game_over = True\n",
    "\n",
    "            game.change_turn()\n",
    "\n",
    "    print(f\"Out of {games} games:\")\n",
    "    print(f\"Wins: {wins}\")\n",
    "    print(f\"Losses: {losses}\")\n",
    "    print(f\"Ties: {ties}\")\n",
    "\n",
    "# Example of using this function\n",
    "play_against_random(agent, games=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
